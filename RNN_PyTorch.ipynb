{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr2rU0xYDvIhVpGbyM7INr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aeagon07/Pytourch/blob/main/RNN_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "WjldICPXcMHu",
        "outputId": "5e9b1107-6333-4090-c8a4-2632d861c44f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11e19508-4bf6-4cd7-8cbe-ff6811e94aa8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11e19508-4bf6-4cd7-8cbe-ff6811e94aa8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 100_Unique_QA_Dataset.csv to 100_Unique_QA_Dataset.csv\n",
            "User uploaded file \"100_Unique_QA_Dataset.csv\" with length 4284 bytes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1657e42-e879-442b-b2ba-85ae2fa9dfdb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1657e42-e879-442b-b2ba-85ae2fa9dfdb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1657e42-e879-442b-b2ba-85ae2fa9dfdb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1657e42-e879-442b-b2ba-85ae2fa9dfdb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4c79ea0-1553-4ea2-af4c-189008facc87\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4c79ea0-1553-4ea2-af4c-189008facc87')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4c79ea0-1553-4ea2-af4c-189008facc87 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Check the uploaded filenames\n",
        "for filename in uploaded.keys():\n",
        "    print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n",
        "\n",
        "# Step 3: Load into pandas dataframe (if it's a CSV)\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text.replace(',', ' ')\n",
        "  text.replace('.', ' ')\n",
        "  text.replace('?', ' ')\n",
        "  text.replace(\"'\", \" \")\n",
        "  return text.split()\n",
        "# ['what', 'is', 'the', 'capital', 'of', 'france'] -> it look like this.."
      ],
      "metadata": {
        "id": "8vVB1P6ec25z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab\n",
        "vocab = {'<UNK>': 0}"
      ],
      "metadata": {
        "id": "XMgFnKjkdNjZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "  print(data['question'], data['answer'])\n",
        "  tok_ques = tokenize(data['question'])\n",
        "  tok_ans = tokenize(data['answer'])\n",
        "\n",
        "  # Now merge the both list\n",
        "  merge_list = tok_ques + tok_ans\n",
        "\n",
        "  # Now run the loop on the merged list\n",
        "  for token in merge_list:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab) # what = 1, is = 2, ..\n",
        "      # From the current length of vacab is the number of the each next unique word"
      ],
      "metadata": {
        "id": "d5F1Nh2tejp9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis=1) # axis=1 for complete data in each will process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dP-Y9-pqe4NT",
        "outputId": "f760baab-bf4d-4399-f2d2-546613436010"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the capital of France? Paris\n",
            "What is the capital of Germany? Berlin\n",
            "Who wrote 'To Kill a Mockingbird'? Harper-Lee\n",
            "What is the largest planet in our solar system? Jupiter\n",
            "What is the boiling point of water in Celsius? 100\n",
            "Who painted the Mona Lisa? Leonardo-da-Vinci\n",
            "What is the square root of 64? 8\n",
            "What is the chemical symbol for gold? Au\n",
            "Which year did World War II end? 1945\n",
            "What is the longest river in the world? Nile\n",
            "What is the capital of Japan? Tokyo\n",
            "Who developed the theory of relativity? Albert-Einstein\n",
            "What is the freezing point of water in Fahrenheit? 32\n",
            "Which planet is known as the Red Planet? Mars\n",
            "Who is the author of '1984'? George-Orwell\n",
            "What is the currency of the United Kingdom? Pound\n",
            "What is the capital of India? Delhi\n",
            "Who discovered gravity? Newton\n",
            "How many continents are there on Earth? 7\n",
            "Which gas do plants use for photosynthesis? CO2\n",
            "What is the smallest prime number? 2\n",
            "Who invented the telephone? Alexander-Graham-Bell\n",
            "What is the capital of Australia? Canberra\n",
            "Which ocean is the largest? Pacific-Ocean\n",
            "What is the speed of light in vacuum? 299,792,458m/s\n",
            "Which language is spoken in Brazil? Portuguese\n",
            "Who discovered penicillin? Alexander-Fleming\n",
            "What is the capital of Canada? Ottawa\n",
            "What is the largest mammal on Earth? Whale\n",
            "Which element has the atomic number 1? Hydrogen\n",
            "What is the tallest mountain in the world? Everest\n",
            "Which city is known as the Big Apple? NewYork\n",
            "How many planets are in the Solar System? 8\n",
            "Who painted 'Starry Night'? vangogh\n",
            "What is the chemical formula of water? H2O\n",
            "What is the capital of Italy? Rome\n",
            "Which country is famous for sushi? Japan\n",
            "Who was the first person to step on the Moon? Armstrong\n",
            "What is the main ingredient in guacamole? Avocado\n",
            "How many sides does a hexagon have? 6\n",
            "What is the currency of China? Yuan\n",
            "Who wrote 'Pride and Prejudice'? Jane-Austen\n",
            "What is the chemical symbol for iron? Fe\n",
            "What is the hardest natural substance on Earth? Diamond\n",
            "Which continent is the largest by area? Asia\n",
            "Who was the first President of the United States? George-Washington\n",
            "Which bird is known for its ability to mimic sounds? Parrot\n",
            "What is the longest-running animated TV show? Simpsons\n",
            "What is the smallest country in the world? VaticanCity\n",
            "Which planet has the most moons? Saturn\n",
            "Who wrote 'Romeo and Juliet'? Shakespeare\n",
            "What is the main gas in Earth's atmosphere? Nitrogen\n",
            "How many bones are in the adult human body? 206\n",
            "Which metal is a liquid at room temperature? Mercury\n",
            "What is the capital of Russia? Moscow\n",
            "Who discovered electricity? Benjamin-Franklin\n",
            "Which is the second-largest country by land area? Canada\n",
            "What is the color of a ripe banana? Yellow\n",
            "Which month has 28 days in a common year? February\n",
            "What is the study of living organisms called? Biology\n",
            "Which country is home to the Great Wall? China\n",
            "What do bees collect from flowers? Nectar\n",
            "What is the opposite of 'day'? Night\n",
            "What is the capital of South Korea? Seoul\n",
            "Who invented the light bulb? Edison\n",
            "Which gas do humans breathe in for survival? Oxygen\n",
            "What is the square root of 144? 12\n",
            "Which country has the pyramids of Giza? Egypt\n",
            "Which sea creature has eight arms? Octopus\n",
            "Which holiday is celebrated on December 25? Christmas\n",
            "What is the currency of Japan? Yen\n",
            "How many legs does a spider have? 8\n",
            "Which sport uses a net, ball, and hoop? Basketball\n",
            "Which country is famous for its kangaroos? Australia\n",
            "Who was the first female Prime Minister of the UK? MargaretThatcher\n",
            "Which is the fastest land animal? Cheetah\n",
            "What is the first element on the periodic table? Hydrogen\n",
            "What is the capital of Spain? Madrid\n",
            "Which planet is the closest to the Sun? Mercury\n",
            "Who is known as the father of computers? CharlesBabbage\n",
            "What is the capital of Mexico? MexicoCity\n",
            "How many colors are in a rainbow? 7\n",
            "Which musical instrument has black and white keys? Piano\n",
            "Who discovered the Americas in 1492? ChristopherColumbus\n",
            "Which Disney character has a long nose and grows it when lying? Pinocchio\n",
            "Who directed the movie 'Titanic'? JamesCameron\n",
            "Which superhero is also known as the Dark Knight? Batman\n",
            "What is the capital of Brazil? Brasilia\n",
            "Which fruit is known as the king of fruits? Mango\n",
            "Which country is known for the Eiffel Tower? France\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APv5Mzx4gi_q",
        "outputId": "d8fc1469-b604-4fd1-d259-53d29eb65c40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "337"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert word to index\n",
        "def word_to_index(data, vocab):\n",
        "\n",
        "  index_text = []\n",
        "\n",
        "  for token in tokenize(data):\n",
        "\n",
        "    if token in vocab:\n",
        "      # when in the vocab every word has it's index, we take the first word what search it in vocab take the index we given and append it in index_text\n",
        "\n",
        "      index_text.append(vocab[token])\n",
        "\n",
        "      # After, this our englist statement which looks like ['1', '2', '3', '4'] in this formate\n",
        "    else:\n",
        "      index_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return index_text"
      ],
      "metadata": {
        "id": "D5HQQ0jwdSPH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index(\"what is CampusX\", vocab) # what = 1, is = 2 and campusX is not present in vocab so CampusX = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFdtqr7zdW_0",
        "outputId": "661f1ba8-8783-4ba0-bbcd-5d1fcdfb79af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class QADataset(Dataset):\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    numerical_Q = word_to_index(self.df.iloc[index]['question'], vocab)\n",
        "    numerical_A = word_to_index(self.df.iloc[index]['answer'], vocab)\n",
        "\n",
        "    return torch.tensor(numerical_Q), torch.tensor(numerical_A)"
      ],
      "metadata": {
        "id": "ESJfCCjWiQoc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)\n",
        "\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZuuNudpkJO9",
        "outputId": "76058b29-2146-4529-9916-dff615b45025"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "mEbU8gV0kPCi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, ans in dataloader:\n",
        "  print(question, ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrirHco7klfH",
        "outputId": "72a3829a-2a5b-4456-dba2-ee6a3f894ea2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 42,   2,   3, 217, 142, 175, 218, 176]]) tensor([[219]])\n",
            "tensor([[  1,   2,   3, 106,   5, 107,  19, 108]]) tensor([[109]])\n",
            "tensor([[80, 81, 82, 83, 84, 85, 86]]) tensor([[87]])\n",
            "tensor([[ 10,  77, 114]]) tensor([[115]])\n",
            "tensor([[  1,   2,   3,   4,   5, 247, 248]]) tensor([[249]])\n",
            "tensor([[ 42, 142,   2, 143,  39, 144]]) tensor([[145]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[  1,   2,   3,  17, 118,  85,  86]]) tensor([[119]])\n",
            "tensor([[ 42, 224, 121, 225, 226,  19,  14, 227, 228]]) tensor([[229]])\n",
            "tensor([[  1,   2,   3, 187, 188, 189, 190]]) tensor([[191]])\n",
            "tensor([[ 42, 103,   2,   3, 104]]) tensor([[105]])\n",
            "tensor([[ 10, 320,   3, 321, 322]]) tensor([[323]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 75]]) tensor([[76]])\n",
            "tensor([[ 10,   2,  63,  64,   3, 295,   5, 296]]) tensor([[297]])\n",
            "tensor([[ 10, 146,   3, 147, 282,  95, 283,   5,   3, 284]]) tensor([[285]])\n",
            "tensor([[ 10,  98,   3, 107, 250]]) tensor([[251]])\n",
            "tensor([[  1,   2,   3,   4,   5, 291]]) tensor([[292]])\n",
            "tensor([[ 42, 174,   2,   3,  17, 175, 176]]) tensor([[177]])\n",
            "tensor([[10,  2,  3, 68,  5, 69]]) tensor([[70]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 54]]) tensor([[55]])\n",
            "tensor([[ 42, 120, 121,   3, 122, 123, 124]]) tensor([[125]])\n",
            "tensor([[ 42, 142, 121,   3, 258,   5, 259]]) tensor([[260]])\n",
            "tensor([[ 10,  29, 134, 135]]) tensor([[136]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[ 10, 146,   3, 147, 178,   5,   3,  72, 179]]) tensor([[180]])\n",
            "tensor([[ 80,  81, 300,  83,  19,  14, 301]]) tensor([[87]])\n",
            "tensor([[ 10,  77,   3, 308,  19, 309]]) tensor([[310]])\n",
            "tensor([[ 42, 274, 275,  14, 276, 277, 165, 278]]) tensor([[279]])\n",
            "tensor([[ 42,  18,   2,   3, 293, 149,   3, 294]]) tensor([[212]])\n",
            "tensor([[ 10,  77, 215]]) tensor([[216]])\n",
            "tensor([[ 42, 311, 312, 121,  14, 313, 314, 165, 315, 316, 317, 318]]) tensor([[319]])\n",
            "tensor([[  1,   2,   3, 244,   5, 245]]) tensor([[246]])\n",
            "tensor([[ 42, 142,   2, 143,  39, 182, 280]]) tensor([[281]])\n",
            "tensor([[ 1,  2,  3, 71,  5,  3, 72, 73]]) tensor([[74]])\n",
            "tensor([[  1,   2,   3,  94, 142,  19,   3,  52]]) tensor([[192]])\n",
            "tensor([[ 80,  81, 157, 158,  14, 159, 160]]) tensor([[161]])\n",
            "tensor([[ 10, 146,   3, 147, 148, 149, 150,  85,   3, 151]]) tensor([[152]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[  1,   2,   3, 220,   5,  14, 221, 222]]) tensor([[223]])\n",
            "tensor([[ 42, 324,   2, 325,  63,  64,   3, 326, 327]]) tensor([[328]])\n",
            "tensor([[ 80,  81, 133,  83,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[10, 56,  3, 57,  5, 58]]) tensor([[59]])\n",
            "tensor([[ 80,  81, 202,  83,  19,   3, 203, 204, 205]]) tensor([[206]])\n",
            "tensor([[ 80,  81, 272, 158,  14, 273, 160]]) tensor([[36]])\n",
            "tensor([[ 42, 181,   2,  63,  39, 182, 183, 149, 184, 185]]) tensor([[186]])\n",
            "tensor([[  1,   2,   3, 153,  88,  19, 199, 200]]) tensor([[201]])\n",
            "tensor([[ 42,  88,  89, 252, 253,  19,  39, 254]]) tensor([[255]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[  1,   2,   3, 230,   5, 231, 232, 233]]) tensor([[234]])\n",
            "tensor([[ 42, 266,   2, 267,  85, 268, 269]]) tensor([[270]])\n",
            "tensor([[ 42, 142,   2, 235, 149,   3, 236, 237]]) tensor([[238]])\n",
            "tensor([[  1,   2,   3,   4,   5, 101]]) tensor([[102]])\n",
            "tensor([[  1,   2,   3,  37, 137,   5, 138]]) tensor([[139]])\n",
            "tensor([[ 42, 110,   2, 111,  19, 112]]) tensor([[113]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 42, 302, 303, 121, 304, 165, 305, 306]]) tensor([[307]])\n",
            "tensor([[  1,   2,   3,   4,   5, 140]]) tensor([[141]])\n",
            "tensor([[  1,   2,   3,   4,   5, 298]]) tensor([[299]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 52]]) tensor([[53]])\n",
            "tensor([[ 42,  18, 121,   3, 193, 194]]) tensor([[195]])\n",
            "tensor([[ 1,  2,  3, 71,  5, 54]]) tensor([[271]])\n",
            "tensor([[42, 18,  2, 63, 64,  3, 65, 66]]) tensor([[67]])\n",
            "tensor([[ 1,  2,  3, 60, 25,  5, 26, 19, 61]]) tensor([[62]])\n",
            "tensor([[ 42, 129,   2,  63,  64,   3, 130, 131]]) tensor([[132]])\n",
            "tensor([[  1,   2,   3,   4,   5, 116]]) tensor([[117]])\n",
            "tensor([[  1,   2,   3,   4,   5, 213]]) tensor([[214]])\n",
            "tensor([[ 42, 142,   2,  63,  39,   3, 334, 335]]) tensor([[336]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 256]]) tensor([[257]])\n",
            "tensor([[ 42,   2,   3, 286, 218, 287]]) tensor([[288]])\n",
            "tensor([[  1,   2,   3, 153, 154,  19, 155]]) tensor([[156]])\n",
            "tensor([[  1,   2,   3, 147, 120,  85,   3, 289, 290]]) tensor([[125]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[42, 88, 89, 90, 91, 39, 92]]) tensor([[93]])\n",
            "tensor([[  1,  89, 239, 240, 241, 242]]) tensor([[243]])\n",
            "tensor([[ 42, 207,   2,  14, 208, 209, 210, 211]]) tensor([[212]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[ 1,  2,  3, 94, 95, 96]]) tensor([[97]])\n",
            "tensor([[10, 98,  3, 99]]) tensor([[100]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 168]]) tensor([[169]])\n",
            "tensor([[ 10,  11, 196, 165, 197]]) tensor([[198]])\n",
            "tensor([[ 42, 261, 262, 121, 263, 264]]) tensor([[265]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[  1,   2,   3,   4,   5, 112]]) tensor([[329]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[ 10,  11, 164, 165, 166]]) tensor([[167]])\n",
            "tensor([[  1,   2,   3,  71,   5, 162]]) tensor([[163]])\n",
            "tensor([[  1,   2,   3, 126, 127,  19,   3,  52]]) tensor([[128]])\n",
            "tensor([[  1,   2,   3, 170, 171, 172,  85,  86]]) tensor([[173]])\n",
            "tensor([[ 42, 330,   2,  63,  64,   3, 331,   5, 332]]) tensor([[333]])\n",
            "tensor([[10, 77, 78]]) tensor([[79]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Summary</b>\n",
        "\n",
        "till now you did =>\n",
        "1) Craete tokenization function by doing the splits and remove the extra symbol like ?, '\n",
        "2) Build the vocab by first convert the question and answer to tokenized form then merge them and loop through to check if they present in vocab or not if not then just add in vocab give the index number as the vocab length at that time.\n",
        "3) After apply these features on the data now you create the word to indix function and convert the question and answers into the numerical form using vocab cause they given the index in vocab\n",
        "4) craete the dataset avriable and give them the create class then after you create the dataoader and store the numrical data of question and answer in dataloader variable using the torch util package Dataloader"
      ],
      "metadata": {
        "id": "XK-U49yCk4Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Architecture"
      ],
      "metadata": {
        "id": "jP-VmHY4m_2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embeding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True) # every time you implement the RNN it is mandatory to add batch_first=True\n",
        "    self.out = nn.Linear(64, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, question):\n",
        "    embeded = self.embeding(question)\n",
        "    hidden, final = self.rnn(embeded) # we getting the tuple of len 2\n",
        "    output = self.out(final.squeeze(0)) # before you get the tensor like [1, 1, 337] to [1, 337]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "PNWQcJ5DktS1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(337, embedding_dim=50)"
      ],
      "metadata": {
        "id": "MbjtV111u3q8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = x(dataset[15][0])"
      ],
      "metadata": {
        "id": "w3H-iJtPxOFC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50, 64)"
      ],
      "metadata": {
        "id": "QsPNtdzgxcI6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDT1Gz_TxdnK",
        "outputId": "f4937e28-32cc-4c26-a012-a5a2b3607682"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqq0qsY6xl3q",
        "outputId": "7b4223c6-1f5e-43ad-a626-21939b08bf1c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Sates\n",
        "y(a)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbKyR7rPx1ea",
        "outputId": "97d186db-20b2-4139-d31c-cb2c64023755"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1532,  0.1189,  0.0731,  0.0947, -0.2134, -0.5450,  0.0048, -0.7195,\n",
              "         -0.5346,  0.0391,  0.0524,  0.1200,  0.2588,  0.6805, -0.2770, -0.0393,\n",
              "          0.1188,  0.0440,  0.3582, -0.1315, -0.7036, -0.2045, -0.0102,  0.5497,\n",
              "          0.1679, -0.1507,  0.6358,  0.7161, -0.2386, -0.3418, -0.6506,  0.5275,\n",
              "          0.6777,  0.6981, -0.7300, -0.0194,  0.1244,  0.0634, -0.1682, -0.2559,\n",
              "         -0.0388,  0.5277,  0.5769,  0.1251,  0.4823, -0.3796, -0.1933,  0.0304,\n",
              "          0.3671,  0.0923, -0.4690,  0.0689,  0.6141, -0.7889,  0.1089,  0.7770,\n",
              "         -0.1206,  0.1876, -0.2274,  0.4116,  0.4636, -0.1843,  0.0926, -0.4487],\n",
              "        [-0.6733, -0.4834,  0.3602,  0.3614, -0.4027,  0.1780, -0.1883,  0.6186,\n",
              "          0.7819, -0.1455,  0.0615,  0.5358,  0.1726, -0.4863, -0.1870,  0.2315,\n",
              "         -0.0933, -0.3479, -0.4731,  0.6040,  0.6991,  0.2557,  0.2344,  0.4153,\n",
              "          0.0071, -0.1869,  0.3840,  0.2884,  0.4733,  0.2834, -0.1471,  0.2865,\n",
              "         -0.6623, -0.6707,  0.1211, -0.2941,  0.0514, -0.5670,  0.4839, -0.1598,\n",
              "          0.1430,  0.1740, -0.5439,  0.5182, -0.7193, -0.2137,  0.4680,  0.4017,\n",
              "          0.3921, -0.0812,  0.0636,  0.2186,  0.7959,  0.4724,  0.6189, -0.5868,\n",
              "          0.5250,  0.1229,  0.1645, -0.5858,  0.1016,  0.5984, -0.5205,  0.4961],\n",
              "        [-0.3422, -0.5827,  0.3655,  0.8481, -0.4385, -0.4877,  0.4655,  0.1272,\n",
              "          0.2022,  0.1977,  0.2790,  0.5278, -0.6988,  0.2434,  0.2082, -0.0331,\n",
              "          0.8179, -0.0733,  0.6691,  0.5248, -0.0137, -0.1224, -0.5543, -0.0391,\n",
              "          0.0912, -0.0298,  0.2456, -0.0502, -0.1260, -0.8527,  0.0379,  0.1980,\n",
              "          0.3518, -0.4844, -0.3381, -0.1101, -0.4487,  0.3848, -0.6036,  0.0138,\n",
              "         -0.3375, -0.1138, -0.3411, -0.3244, -0.6073,  0.5209, -0.7907,  0.4658,\n",
              "         -0.3327, -0.5975,  0.2932,  0.2609,  0.5224, -0.8241,  0.5932,  0.3756,\n",
              "          0.6110,  0.7213, -0.6127,  0.2461, -0.0956, -0.0137, -0.3935, -0.4132],\n",
              "        [-0.1327, -0.3929,  0.1310, -0.1471, -0.6205, -0.3983,  0.3262,  0.4215,\n",
              "          0.3142,  0.7178,  0.7817,  0.0301, -0.4085, -0.3617, -0.7364,  0.1102,\n",
              "         -0.3155,  0.4729, -0.0702,  0.0190,  0.5973, -0.3764,  0.0163,  0.2313,\n",
              "          0.0409,  0.0482, -0.6060,  0.0627,  0.1609, -0.4933,  0.2878, -0.4377,\n",
              "         -0.4523, -0.2762,  0.5977, -0.8841, -0.7069,  0.4189, -0.7954,  0.7797,\n",
              "          0.4541, -0.3319,  0.6102, -0.3634,  0.0786,  0.9137,  0.3036, -0.0823,\n",
              "         -0.1786,  0.1082,  0.9557, -0.1404,  0.1754, -0.4069,  0.6165, -0.6190,\n",
              "         -0.7858, -0.0775,  0.8396,  0.0549,  0.8103,  0.8225, -0.1904, -0.3366],\n",
              "        [-0.1790,  0.6151,  0.1298,  0.4404, -0.5554, -0.0021,  0.4819, -0.3875,\n",
              "          0.4950,  0.8083,  0.1662,  0.2086,  0.0677, -0.0307,  0.5784, -0.3174,\n",
              "          0.0193,  0.2390,  0.1816,  0.6209, -0.2138,  0.2661,  0.7944, -0.3994,\n",
              "         -0.6287, -0.1929, -0.0908, -0.3853,  0.1689, -0.2440,  0.3041, -0.0898,\n",
              "          0.3190,  0.3808, -0.5582, -0.1642, -0.4685, -0.5815, -0.3451,  0.5039,\n",
              "         -0.2858, -0.5504, -0.3994,  0.0085, -0.5412,  0.7989,  0.7517, -0.1900,\n",
              "         -0.7013, -0.4497,  0.5318,  0.0537,  0.2849, -0.1776, -0.2265,  0.2436,\n",
              "          0.3378, -0.0155,  0.7312,  0.2205,  0.5234, -0.2065, -0.0557,  0.4164],\n",
              "        [-0.2012, -0.6867,  0.4120,  0.8368, -0.6801, -0.4893,  0.3013,  0.1144,\n",
              "         -0.2595,  0.2126,  0.0475,  0.1880, -0.4286, -0.2619, -0.1661, -0.2725,\n",
              "          0.8888, -0.2618,  0.6437,  0.6792,  0.0371, -0.1248,  0.3059,  0.3913,\n",
              "          0.5843,  0.0037,  0.4093,  0.2257, -0.0524, -0.9257, -0.5073,  0.2035,\n",
              "          0.1170, -0.6734, -0.3331, -0.2208, -0.0459,  0.2017, -0.4096,  0.1332,\n",
              "         -0.1025, -0.1098, -0.2102, -0.2431, -0.7796,  0.5704, -0.5989,  0.0684,\n",
              "         -0.2269, -0.6320,  0.1118,  0.3824,  0.8310, -0.8813,  0.4533,  0.3706,\n",
              "          0.8317,  0.6454, -0.3787,  0.4148, -0.0449, -0.0829, -0.3789,  0.0570],\n",
              "        [-0.3980, -0.7112,  0.0849,  0.4271, -0.1804, -0.5692, -0.4578, -0.0712,\n",
              "          0.3951,  0.4673,  0.6185, -0.2451, -0.0601,  0.0375, -0.8185, -0.1491,\n",
              "         -0.1629,  0.3190,  0.0653,  0.3645,  0.3063,  0.2016,  0.5657,  0.3382,\n",
              "         -0.2842,  0.0709, -0.2684, -0.7911, -0.1256, -0.2354, -0.1070,  0.6153,\n",
              "          0.1973,  0.3589, -0.0567, -0.1647,  0.7169,  0.1590, -0.0223, -0.3130,\n",
              "         -0.8304,  0.0610,  0.3728,  0.7483, -0.2494,  0.7033, -0.1000, -0.8920,\n",
              "          0.0807,  0.4366,  0.6962, -0.0194,  0.6611, -0.3765,  0.1962,  0.4210,\n",
              "          0.0661,  0.0248, -0.1219, -0.2485, -0.6926,  0.3034, -0.2822, -0.1098],\n",
              "        [-0.7410,  0.2258, -0.3763,  0.7941,  0.3092, -0.4885,  0.0438,  0.8101,\n",
              "          0.4896,  0.2851, -0.3265, -0.6994,  0.0989, -0.0729, -0.6138,  0.2746,\n",
              "          0.6511,  0.7484,  0.2499, -0.3189,  0.0856,  0.2479, -0.2135,  0.2840,\n",
              "         -0.2909, -0.4387,  0.8752,  0.0458,  0.3222, -0.6270, -0.0900,  0.1259,\n",
              "         -0.1841, -0.3759, -0.0324, -0.0518,  0.6834, -0.1501,  0.8314,  0.5132,\n",
              "         -0.6298,  0.7410,  0.2347,  0.4476, -0.1169,  0.6789, -0.1795, -0.1569,\n",
              "         -0.0393,  0.2474,  0.1510,  0.8312,  0.8122, -0.5584,  0.1120,  0.7374,\n",
              "          0.2736,  0.0445,  0.6828, -0.0079,  0.2009, -0.4644,  0.4373, -0.2661]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Output\n",
        "y(a)[1]\n",
        "\n",
        "# Here we get the two ouputs from RNN() so we cann't use the sequential layer here that's why you have to write the manually the forward function.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggDBQcQExp34",
        "outputId": "e4af50b2-a592-4d99-dd14-e432414d3904"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7410,  0.2258, -0.3763,  0.7941,  0.3092, -0.4885,  0.0438,  0.8101,\n",
              "          0.4896,  0.2851, -0.3265, -0.6994,  0.0989, -0.0729, -0.6138,  0.2746,\n",
              "          0.6511,  0.7484,  0.2499, -0.3189,  0.0856,  0.2479, -0.2135,  0.2840,\n",
              "         -0.2909, -0.4387,  0.8752,  0.0458,  0.3222, -0.6270, -0.0900,  0.1259,\n",
              "         -0.1841, -0.3759, -0.0324, -0.0518,  0.6834, -0.1501,  0.8314,  0.5132,\n",
              "         -0.6298,  0.7410,  0.2347,  0.4476, -0.1169,  0.6789, -0.1795, -0.1569,\n",
              "         -0.0393,  0.2474,  0.1510,  0.8312,  0.8122, -0.5584,  0.1120,  0.7374,\n",
              "          0.2736,  0.0445,  0.6828, -0.0079,  0.2009, -0.4644,  0.4373, -0.2661]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = y(a)[1]"
      ],
      "metadata": {
        "id": "gCFzZ-1ixxbp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64, 337)"
      ],
      "metadata": {
        "id": "Obj9J6uJzRMJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z(b).shape\n",
        "\n",
        "# For each word in your vacab you are getting the proabbility, And you select those word that are higher probbability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfsdT4LozUJE",
        "outputId": "d2cfc671-98fb-4d4d-b069-53ccc1cbfc54"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 337])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imporatant Variable\n",
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "ENim5JJCzXpP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "tKK68g260wzJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "DYYWCgRR04k9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traning Loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, ans in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    prediction = model(question)\n",
        "\n",
        "    # Loss => when you going to calculate the loss it should be like your output shape (1, 324) - (1) for every questions answer\n",
        "    # what was the problem is our shape is not comming correct\n",
        "    loss = criterion(prediction, ans.squeeze(1)) # Flatten the target tensor\n",
        "\n",
        "    # Gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utTOEOHm1QIS",
        "outputId": "27c1bd0a-9c4f-4278-ac60-778e5a908b22"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 527.657507\n",
            "Epoch: 2, Loss: 461.169780\n",
            "Epoch: 3, Loss: 381.245202\n",
            "Epoch: 4, Loss: 317.316531\n",
            "Epoch: 5, Loss: 265.750501\n",
            "Epoch: 6, Loss: 218.847295\n",
            "Epoch: 7, Loss: 175.432518\n",
            "Epoch: 8, Loss: 138.029305\n",
            "Epoch: 9, Loss: 106.208721\n",
            "Epoch: 10, Loss: 81.125805\n",
            "Epoch: 11, Loss: 62.466459\n",
            "Epoch: 12, Loss: 48.491076\n",
            "Epoch: 13, Loss: 38.684943\n",
            "Epoch: 14, Loss: 31.315406\n",
            "Epoch: 15, Loss: 25.784509\n",
            "Epoch: 16, Loss: 21.584440\n",
            "Epoch: 17, Loss: 18.271634\n",
            "Epoch: 18, Loss: 15.605916\n",
            "Epoch: 19, Loss: 13.457724\n",
            "Epoch: 20, Loss: 11.570375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans.squeeze(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrZqgLXM4yGW",
        "outputId": "f154511b-7775-419f-a5f7-3ba924c46cea"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([186])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "\n",
        "def predict(model, question, threshold = 0.5):\n",
        "\n",
        "  # Question to Number\n",
        "  num_ques = word_to_index(question, vocab)\n",
        "\n",
        "  # Tensor\n",
        "  Q_tens = torch.tensor(num_ques).unsqueeze(0) # get into perfect shape\n",
        "\n",
        "  # Send to Model\n",
        "  out = model(Q_tens)\n",
        "\n",
        "  # print(out.shape) # => Gives you Logits - [1, 337]\n",
        "\n",
        "  # convert logit to probabiliy\n",
        "  probs = torch.nn.functional.softmax(out, dim=1)\n",
        "\n",
        "  # Find max probs\n",
        "  value, index_max = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index_max])"
      ],
      "metadata": {
        "id": "9OXuBjFt6Krp"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the smallest country in the world?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGWh20psA3hh",
        "outputId": "1f24ff8f-2d83-4059-937e-1910adef3bc7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vaticancity\n"
          ]
        }
      ]
    }
  ]
}