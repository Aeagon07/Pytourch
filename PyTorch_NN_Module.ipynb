{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPqNXQYNX7PmjFaCNN7m9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aeagon07/Pytourch/blob/main/PyTorch_NN_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H9iOPsBa3al6"
      },
      "outputs": [],
      "source": [
        "#  Create the model class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create the class\n",
        "class Model(nn.Module):\n",
        "  # You must inherite the our model class from the nn module class\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__() # here you invoke the nn module class\n",
        "\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "# In Pytorch the functions are already defines so if you change the name of the function then it not run properly\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x) # z = wx + b\n",
        "    out = self.sigmoid(out) # doing Activation sigmod(z)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "features = torch.rand(10, 5)\n",
        "\n",
        "# create model\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "# call model for forward pass\n",
        "# model.forward_pass(features) -> you can do this way too but in pT recommanded you to don't do this way instead of use below approach\n",
        "model(features)\n",
        "\n",
        "# What we doing is create the model object and simply call it as the funtion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE1o9wwi7DYU",
        "outputId": "7e789888-f81b-4eef-d4f7-28a09f3e8fdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6986],\n",
              "        [0.6473],\n",
              "        [0.6387],\n",
              "        [0.7013],\n",
              "        [0.6278],\n",
              "        [0.7028],\n",
              "        [0.6430],\n",
              "        [0.6338],\n",
              "        [0.6792],\n",
              "        [0.6377]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUkTDD8W9IKC",
        "outputId": "aaa3d7bc-73de-4508-de29-8e9b011aae6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.2527, 0.0035, 0.0583, 0.3576, 0.1451]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jecw4su_g9j",
        "outputId": "60dade44-991c-495b-cb9f-5b9f9099f7ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.3328], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to visulalize the whole network as you done in keras and all then\n",
        "# you have the in build libray\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl0daQlX_FUG",
        "outputId": "8599ac26-58db-4932-9e6c-2b74b13696e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(10, 5))\n",
        "\n",
        "# Why 6 -> 5 parameters and 1 bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3OAjrF__IC",
        "outputId": "bc518606-ef0b-4029-e8bb-05ad260acf2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 1]                   6\n",
              "├─Sigmoid: 1-2                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improved Neutral Network"
      ],
      "metadata": {
        "id": "8nMfEizRCZD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #  Create the model class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create the class\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear1 = nn.Linear(num_features, 3) # how many outcome you will take when first inputs are going\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(3, 1) # It takes 3 input and give the 1 output\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x) # z = wx + b\n",
        "    out = self.relu(out) # doing Activation sigmod(z)\n",
        "\n",
        "    out = self.linear2(out)\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "97Nglt4VAhcZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "features = torch.rand(10, 5)\n",
        "\n",
        "# create model\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "# call model for forward pass\n",
        "model(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XD39i4rD3Td",
        "outputId": "f970a07d-9264-4beb-ce68-e66a11b793fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6230],\n",
              "        [0.6024],\n",
              "        [0.5952],\n",
              "        [0.6014],\n",
              "        [0.5976],\n",
              "        [0.5855],\n",
              "        [0.6173],\n",
              "        [0.5982],\n",
              "        [0.5995],\n",
              "        [0.5832]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.weight # Must give -> 5*3 = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6coq5yLkD_9A",
        "outputId": "efdd182d-f956-4ea6-b459-c5fc582764d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4315,  0.1666, -0.2162, -0.1590,  0.2988],\n",
              "        [ 0.1809,  0.1525, -0.4004, -0.0823,  0.0284],\n",
              "        [-0.1239,  0.1863, -0.4046, -0.1123,  0.3767]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.weight # Must Give -> 3*1 = 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgcTD8mlECSP",
        "outputId": "1ee36072-de83-4a66-fdfa-bc4578563325"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4722, -0.3509,  0.0270]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear1.bias # Must Give -> 3 bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ug8qfzkEHHG",
        "outputId": "066a782d-301b-4888-a479-efdedbc738c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.1012,  0.3076,  0.0333], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear2.bias# Must Give -> 1 bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H1F3JQTELri",
        "outputId": "4dba8c4b-e7b2-46f0-f82f-19df55a5bc50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.4195], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kkTDRbsENvh",
        "outputId": "d6a8a4ff-0bc8-4256-f32a-675c0c33040f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(10, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqoOpxhfEwun",
        "outputId": "1c9bb9cb-7a2b-4dbf-953c-7e2f2ac47d86"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 3]                   18\n",
              "├─ReLU: 1-2                              [10, 3]                   --\n",
              "├─Linear: 1-3                            [10, 1]                   4\n",
              "├─Sigmoid: 1-4                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 22\n",
              "Trainable params: 22\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the Sequential Container intsead of repeating and going from each layer"
      ],
      "metadata": {
        "id": "F-1XmM_-FPII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #  We only write the changes here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create the class\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "      nn.Linear(num_features, 3) ,\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(3, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.network(x)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "BRVSGBSzE9-p"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optim Module**"
      ],
      "metadata": {
        "id": "Wbqm0oXZNsua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define optizer !\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=25) # Try to execute it after model creation\n",
        "\n",
        "# model.parameters is basically the iterator over all the trainable parameters(weights and biases) => It means if you want to access the all the\n",
        "# parameters in your defined model they you have to use the model.parameters()\n",
        "\n",
        "# Then calll\n",
        "optimizer.step()\n",
        "\n",
        "# And Take care of the gradient zeros is done by single line of the code\n",
        "optimizer.zero_grad()\n",
        "# -> This pass is better to run before the backward() pass"
      ],
      "metadata": {
        "id": "84ppXda4N4f8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}